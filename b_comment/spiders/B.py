import jsonimport randomimport reimport scrapyimport timefrom scrapy import Requestfrom ..items import BCommentItemclass bilibili(scrapy.Spider):    name = "bilibili"  #改项目名称    host = "https://api.bilibili.com"  #爬取网站host    # 构造api列表    # start_urls = ["https://api.bilibili.com/x/v2/reply?oid=95366524&type=1&sort=2&pn={}".format(p) for p in range(1,771)]    start_urls = ['https://api.bilibili.com/x/v2/reply?oid=73836578&type=1&sort=2&pn={}'.format(p) for p in range(1,268)]    def start_requests(self):        for url in self.start_urls:            # 此处将起始url加入scrapy的待爬取队列，并指定解析函数            # scrapy会自行调度，并访问该url然后把内容拿回来            yield Request(url=url, callback=self.parse_page) #请求api            time.sleep(random.uniform(2,8)) #降低爬取频率，避免反爬    #版面解析函数，解析评论和时间    def parse_page(self, response):        info = response.body.decode('UTF-8') #返回为乱码，需要改编码        info_json = json.loads(info) #改json格式        item = BCommentItem()        info_len = len(info_json['data']['replies']) #确定评论数，下面做解析        for i in range(info_len):            item['content'] = info_json['data']['replies'][i]['content']['message'] # 评论内容            times = info_json['data']['replies'][i]['ctime'] # 评论时间            item['time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(times)) #因为返回的为时间戳，需转为时间日期格式            replies = info_json['data']['replies'][i]['replies'] # 确定追加评论数，下面做解析            print(item)            yield item # 返回得到的数据            if replies:                # 以下和主评论一样，不一一说明                for r in range(len(replies)):                    item['content'] = info_json['data']['replies'][i]['replies'][r]['content']['message']                    times = info_json['data']['replies'][i]['replies'][r]['ctime']                    item['time'] = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(times))                    print(item)                    yield item